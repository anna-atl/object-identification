{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is needed for preparing the input datasets: upper case and etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The input datasets should be in the following format:\n",
    "- Company name (string)\n",
    "- Marketplace (string)\n",
    "- Country (string)\n",
    "- State (string)\n",
    "- City (string)\n",
    "- Zip Code (string)\n",
    "- Street (string)\n",
    "- URL (string)\n",
    "- Industry (SIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import sys\n",
    "import numpy as np\n",
    "import string\n",
    "import collections\n",
    "from textblob import TextBlob\n",
    "import Levenshtein\n",
    "import binascii\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_import():\n",
    "    # import FR data (adjustments for delimeters and encoding - latin)\n",
    "    df = pd.read_csv(\"~/Dropbox/Botva/TUM/Master_Thesis/datasets/processed_files/france_rna_processed.csv\", encoding='latin-1', sep = ';', error_bad_lines=False) \n",
    "#    df = pd.read_csv(\"~/Dropbox/Botva/TUM/Master_Thesis/object-identification/datasets/raw_files/rna_waldec_20201201_dpt_01.csv\", error_bad_lines=False)\n",
    "#    df = df.astype(str)\n",
    "    print(df)\n",
    "    print(df.dtypes)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_prepare(df):\n",
    "    df = df.apply(lambda x: x.astype(str).str.upper())\n",
    "    df['name'] = df['name'].apply(lambda x: x.replace('.',''))\n",
    "    df['name'] = df['name'].str.replace('[^0-9a-zA-Z]+', ' ')\n",
    "    df['name'] = df['name'].str.replace(' +', ' ')\n",
    "    df['name_split'] = df['name'].str.split(' ')\n",
    "    print(df)\n",
    "    print(df.dtypes)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequent_words(df_processed):\n",
    "    b = TextBlob(\"bonjour\")\n",
    "    b.detect_language()\n",
    "    print(df_processed['name'])\n",
    "    all_words = df_processed['name']    \n",
    "    all_words_cleaned = []\n",
    "\n",
    "    for text in all_words:\n",
    "        text = [x.strip(string.punctuation) for x in text]\n",
    "        all_words_cleaned.append(text)\n",
    "\n",
    "    all_words_cleaned[0]\n",
    "\n",
    "    text_words = [\" \".join(text) for text in all_words_cleaned]\n",
    "    final_text_words = \" \".join(text_words)\n",
    "    #final_text_words[:1000]\n",
    "\n",
    "    print(all_words)\n",
    "    stopwords = set(STOPWORDS)\n",
    "    stopwords.update([\"LE\",\"DE\",\"LA\",\"ET\",\"DES\",\"DU\",\"LES\",\"EN\",\"ET\",\"A\",\"POUR\",\"SUR\",\"SOU\",\"S\",\"D\",\"L\"])\n",
    "\n",
    "    wordcloud_names = WordCloud(stopwords=stopwords, background_color=\"white\", max_font_size=50, max_words=100).generate(final_text_words)\n",
    "\n",
    "    # Lines 4 to 7\n",
    "    plt.figure(figsize = (15,15))\n",
    "    plt.imshow(wordcloud_names, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    filtered_words = [word for word in final_text_words.split() if word not in stopwords]\n",
    "    counted_words = collections.Counter(filtered_words)\n",
    "\n",
    "    word_count = {}\n",
    "\n",
    "    for letter, count in counted_words.most_common(100):\n",
    "        word_count[letter] = count\n",
    "\n",
    "    for i,j in word_count.items():\n",
    "        print('Word: {0}, count: {1}'.format(i,j))\n",
    "    \n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Levenstein Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_1 = df_processed['name']\n",
    "texts_2 = df_processed['name']\n",
    "lvn_array = np.zeros((len(texts_1),len(texts_2)))\n",
    "print(lvn_array)\n",
    "\n",
    "text_1_num = 0\n",
    "text_2_num = 0\n",
    "\n",
    "for text_1 in texts_1:\n",
    "    for text_2 in texts_2:\n",
    "        lvn_array[text_1_num,text_2_num] = Levenshtein.ratio(text_1,text_2)\n",
    "        text_2_num += 1 \n",
    "    text_2_num = 0    \n",
    "    text_1_num += 1 \n",
    "lvn_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_import()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = df_prepare(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df_processed['name']\n",
    "\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating shingles_dict\n",
    "n = 2\n",
    "shingles_list = set()\n",
    "\n",
    "for text in texts:\n",
    "#    print(text)\n",
    "#    text = text.encode()\n",
    "    shingles = [text[i:i + n] for i in range(len(text) - n + 1)]\n",
    "#    print(shingles)\n",
    "    for shingle in shingles:\n",
    "        if shingle not in shingles_list: #check, maybe if is not needed bc its a set\n",
    "            shingles_list.add(shingle)\n",
    "    \n",
    "shingles_list = sorted(shingles_list)\n",
    "shingles_dict = dict(zip(shingles_list,range(len(shingles_list))))\n",
    "shingles_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shingles_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting docs to shingles\n",
    "docs = [[] for i in range(len(df_processed['name']))]\n",
    "\n",
    "for doc, text in zip(docs, texts):\n",
    "    shingles = [text[i:i + n] for i in range(len(text) - n + 1)]    \n",
    "    for shingle in shingles:\n",
    "        doc.append(shingles_dict[shingle])\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating signatures array\n",
    "signature_size = 50 #signature size\n",
    "signatures = np.zeros((signature_size, len(docs))) #create an array\n",
    "\n",
    "shingles_shuffled = [i for i in range(len(shingles_list))]\n",
    "\n",
    "for signature in signatures:\n",
    "    random.shuffle(shingles_shuffled)    \n",
    "    for doc_index, doc in enumerate(docs):\n",
    "        doc_a = [shingles_shuffled[i] for i in doc]\n",
    "        signature[doc_index] = min(doc_a)\n",
    "\n",
    "signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bands = 5 #number of bands\n",
    "r = int(len(signatures)/bands) #rows per band\n",
    "\n",
    "def jaccard(list1, list2):\n",
    "#    print(len(list(set(list1).intersection(list2))))\n",
    "    intersection = len(set(list1).intersection(list2))\n",
    "#    print(len(list1))\n",
    "    union = (len(set(list1)) + len(set(list2))) - intersection\n",
    "    return intersection/union\n",
    "\n",
    "print(signatures[:,0])\n",
    "print(jaccard(docs[0], docs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "a = len(signatures[0])\n",
    "bucket = {}\n",
    "\n",
    "for band in range(bands):\n",
    "    for i in range(len(signatures[0])):\n",
    "    #    t0 = time.time()\n",
    "        for j in range(len(signatures[0])):\n",
    "            if i<j:\n",
    "                if jaccard(signatures[band*r:band*r+r,i], signatures[band*r:band*r+r,j])>threshold:\n",
    "#                    print(jaccard(signatures[band*r:band*r+r,i], signatures[band*r:band*r+r,j]))\n",
    "#                    print(i,j)\n",
    "                    print(texts[i])\n",
    "                    print(texts[j])\n",
    "                    bucket.setdefault(i,[]).append(j)\n",
    "                    print(bucket)\n",
    "    #    elapsed = (time.time() - t0)            \n",
    "    #    print(\"\\nChecking one doc to all others took %.2fsec\" % elapsed)  \n",
    "    #    b = (a-i)*elapsed/60/60\n",
    "    #    print(\"\\nExpected left time: %.2fhours\" % b)  \n",
    " \n",
    "\n",
    "\n",
    "#compare row by row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(len(d) for d in texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Levenshtein.ratio(df_processed['name'],df_processed['name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textdistance import levenshtein\n",
    "\n",
    "df_1 = df_processed['name']\n",
    "df_2 = df_processed['name']\n",
    "df_1.apply(lambda x: levenshtein.distance(df_1['name'], df_2['name']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install textdistance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
