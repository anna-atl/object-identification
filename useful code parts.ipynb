{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Annie/Dropbox/Botva/TUM/Master_Thesis/object-identification\n",
      "/Users/Annie/Dropbox/Botva/TUM/Master_Thesis/object-identification/france_rna_processed.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "#checks current dir\n",
    "print(os.getcwd())\n",
    "#checks location of the file\n",
    "print(os.path.abspath(\"france_rna_processed.csv\"))\n",
    "#checks if folder in dir\n",
    "os.path.isdir('Dropbox')\n",
    "#checks if file is in dir\n",
    "os.path.exists(os.path.join(os.getcwd(), 'france_rna_processed.csv'))\n",
    "#checks if file is somewhere\n",
    "os.path.isfile('../Dropbox/Dropbox/Botva/TUM/Master_Thesis/object-identification/france_rna_processed.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upgrading pip\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "#installing a lib\n",
    "!{sys.executable} -m pip install wordcloud\n",
    "#checks where is pip, python\n",
    "!type pip\n",
    "!type python\n",
    "#checks where is executable\n",
    "sys.executable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wordcloud without stopwords\n",
    "wordcloud_names = WordCloud(background_color=\"white\").generate(final_text_words)\n",
    "\n",
    "# Lines 2 - 5\n",
    "plt.figure(figsize = (20,20))\n",
    "plt.imshow(wordcloud_names, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: {sys.executable}: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python is /usr/bin/python\n",
      "pip is /usr/local/bin/pip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/usr/local/opt/python/bin/python3.7'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "!type python\n",
    "!type pip\n",
    "sys.executable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old shingles generation\n",
    "\n",
    "n = 2\n",
    "shingles_list = []\n",
    "\n",
    "texts = df_processed['name']\n",
    "hashes_list = np.array([0] * len(df_processed['name']))\n",
    "hashes_array = hashes_list\n",
    "\n",
    "text_num = 0\n",
    "shingle_num = 0\n",
    "\n",
    "for text in texts:\n",
    "#    print(text)\n",
    "#    text = text.encode()\n",
    "    shingles = [text[i:i + n] for i in range(len(text) - n + 1)]\n",
    "#    print(shingles)\n",
    "    for shingle in shingles:\n",
    "        if shingle not in shingles_list:\n",
    "            hashes_array = np.vstack((hashes_array, hashes_list)) #needs to be removed after last iteration\n",
    "            shingles_list.append(shingle)\n",
    "            hashes_array[shingle_num,text_num] = 1\n",
    "            shingle_num += 1\n",
    "        if shingle in shingles_list:\n",
    "            hashes_array[shingles_list.index(shingle),text_num] = 1\n",
    "    text_num += 1\n",
    "    \n",
    "hashes_array\n",
    "\n",
    "\n",
    "#signatures = [[] for i in range(len(signature_size))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trash\n",
    "\n",
    "\n",
    "    for num, name in enumerate(presidents, start=1):\n",
    "    print(\"President {}: {}\".format(num, name))\n",
    "    \n",
    "    for shingle in shingles_shuffled:\n",
    "        while all columns of signature are filled:\n",
    "            signature[doc] = shingle[doc] \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for i, doc in zip(signature,docs):\n",
    "        shingles_dict_sh\n",
    "        i = doc[shingle]\n",
    "            print(signatures)\n",
    "            break\n",
    "#             = \n",
    "        break\n",
    "    break\n",
    "x =+ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [{} for i in range(len(df_processed['name']))]\n",
    "\n",
    "#hashes_array = np.zeros((len(shingles_list), len(df_processed['name'])))\n",
    "\n",
    "for doc, text in zip(docs, texts):\n",
    "    shingles = [text[i:i + n] for i in range(len(text) - n + 1)]    \n",
    "    for shingle in shingles:\n",
    "        doc[shingle] = shingles.index(shingle)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hashes_array = np.zeros((len(shingles_list), len(df_processed['name'])))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
